{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNiKHf6xZoyhIC8aYajrox5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"jV0dVvarm2lp","executionInfo":{"status":"ok","timestamp":1731359213259,"user_tz":-480,"elapsed":4763,"user":{"displayName":"Chenxu Zhu","userId":"14514250004667300911"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["class ImprovedCNN(nn.Module):\n","    def __init__(self, num_classes=3):  # Updated to reflect 3 output classes if needed\n","        super(ImprovedCNN, self).__init__()\n","\n","        # Convolutional block 1\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=(5, 15), stride=(2, 2), padding=(2, 2)),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n","        )\n","\n","        # Convolutional block 2\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(32, 64, kernel_size=(3, 7), stride=(2, 2), padding=(1, 1)),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n","        )\n","\n","        # Convolutional block 3\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(1, 1)),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n","        )\n","\n","        # Fully connected layers\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(6656, 256)  # Adjusted based on output dimensions\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, num_classes)\n","\n","        # Dropout layer\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, x):\n","      # Convolutional layers\n","      x = self.conv1(x)\n","      x = self.conv2(x)\n","      x = self.conv3(x)\n","\n","      # Flatten the features\n","      x = self.flatten(x)\n","\n","      # Fully connected layers with dropout\n","      x = F.relu(self.fc1(x))\n","      x = self.dropout(x)\n","      x = F.relu(self.fc2(x))\n","      x = self.dropout(x)\n","      x = self.fc3(x)\n","\n","      return x\n","\n","\n","\n","# Instantiate the improved model\n","model = ImprovedCNN(num_classes=3)  # Updated to reflect the potential multi-label task\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"47FtY47KnfiP","executionInfo":{"status":"ok","timestamp":1731359216426,"user_tz":-480,"elapsed":327,"user":{"displayName":"Chenxu Zhu","userId":"14514250004667300911"}},"outputId":"73911d85-4eb3-46fe-e93d-41841dd4c8e6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["ImprovedCNN(\n","  (conv1): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(5, 15), stride=(2, 2), padding=(2, 2))\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(3, 7), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv3): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (fc1): Linear(in_features=6656, out_features=256, bias=True)\n","  (fc2): Linear(in_features=256, out_features=128, bias=True)\n","  (fc3): Linear(in_features=128, out_features=3, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gyQmOtg4n3hZ","executionInfo":{"status":"ok","timestamp":1731359241580,"user_tz":-480,"elapsed":23683,"user":{"displayName":"Chenxu Zhu","userId":"14514250004667300911"}},"outputId":"cc0d7c62-a4e5-47e1-a0fc-b48f6b27868a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch.optim as optim\n","import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/CNN_Test')\n","\n","from EEGEyeNet import EEGEyeNetDataset\n"],"metadata":{"id":"372OOqEMogPt","executionInfo":{"status":"ok","timestamp":1731359246883,"user_tz":-480,"elapsed":3243,"user":{"displayName":"Chenxu Zhu","userId":"14514250004667300911"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader"],"metadata":{"id":"6m3OtuUqaUhY","executionInfo":{"status":"ok","timestamp":1731359250636,"user_tz":-480,"elapsed":2304,"user":{"displayName":"Chenxu Zhu","userId":"14514250004667300911"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Define paths\n","data_file_path = '/content/drive/MyDrive/Colab Notebooks/Position_task_with_dots_synchronised_min.npz'\n","\n","# Create dataset instance\n","train_dataset = EEGEyeNetDataset(data_file_path, transpose=True)\n","\n","# Split dataset into training and validation sets\n","train_size = int(0.8 * len(train_dataset))\n","val_size = len(train_dataset) - train_size\n","train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n","\n","# Create DataLoader\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Instantiate the model\n","output_size = 2  # Assuming output size is known and matches the label dimensions\n","model = ImprovedCNN(num_classes=output_size)\n","model = model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.MSELoss()  # For regression tasks\n","criterion = criterion.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n","\n","# Training loop\n","epochs = 15\n","print(\"Starting training...\")\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1} started...\")\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels, _ in train_loader:  # Third return value is index, not used\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","\n","        # Calculate loss\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    # Print epoch loss\n","    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n","\n","    # Validation step\n","    model.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for inputs, labels, _ in val_loader:\n","            inputs, labels = inputs.to('cuda' if torch.cuda.is_available() else 'cpu'), labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","    print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n","\n","print('Training completed.')\n","\n","# Save the trained model\n","torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/CNN_Test/trained_model.pth')\n","\n"],"metadata":{"id":"RLKyaxcFprAk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"80f8afca-199e-4cef-ff37-255b6b6138f1","executionInfo":{"status":"ok","timestamp":1731360152461,"user_tz":-480,"elapsed":898673,"user":{"displayName":"Chenxu Zhu","userId":"14514250004667300911"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n","[[  1.  408.1 315.1]\n"," [  1.  640.7 519.1]\n"," [  1.  404.2 118.8]\n"," ...\n"," [177.  115.5 306.1]\n"," [177.  732.  310.3]\n"," [177.  632.2 353.6]]\n","Starting training...\n","Epoch 1 started...\n","Epoch [1/15], Loss: 45992.2378\n","Validation Loss: 26308.3894\n","Epoch 2 started...\n","Epoch [2/15], Loss: 27459.6587\n","Validation Loss: 19152.6550\n","Epoch 3 started...\n","Epoch [3/15], Loss: 23382.1772\n","Validation Loss: 20760.6573\n","Epoch 4 started...\n","Epoch [4/15], Loss: 22549.6369\n","Validation Loss: 20446.4031\n","Epoch 5 started...\n","Epoch [5/15], Loss: 21758.5322\n","Validation Loss: 18337.4681\n","Epoch 6 started...\n","Epoch [6/15], Loss: 21227.5086\n","Validation Loss: 22000.7029\n","Epoch 7 started...\n","Epoch [7/15], Loss: 21049.0194\n","Validation Loss: 18387.2213\n","Epoch 8 started...\n","Epoch [8/15], Loss: 20605.7098\n","Validation Loss: 17912.7505\n","Epoch 9 started...\n","Epoch [9/15], Loss: 20221.2188\n","Validation Loss: 21573.0363\n","Epoch 10 started...\n","Epoch [10/15], Loss: 20067.8631\n","Validation Loss: 18018.0656\n","Epoch 11 started...\n","Epoch [11/15], Loss: 19756.6807\n","Validation Loss: 19574.3968\n","Epoch 12 started...\n","Epoch [12/15], Loss: 19408.2338\n","Validation Loss: 17852.0479\n","Epoch 13 started...\n","Epoch [13/15], Loss: 19086.5436\n","Validation Loss: 20557.1874\n","Epoch 14 started...\n","Epoch [14/15], Loss: 18991.8471\n","Validation Loss: 17913.9153\n","Epoch 15 started...\n","Epoch [15/15], Loss: 18834.4871\n","Validation Loss: 16608.3375\n","Training completed.\n"]}]},{"cell_type":"code","source":["print(\"CUDA available:\", torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lfBjd4w72I8A","executionInfo":{"status":"ok","timestamp":1731197036649,"user_tz":-480,"elapsed":331,"user":{"displayName":"Chenxu Zhu","userId":"14514250004667300911"}},"outputId":"e160d8dd-a145-49fc-ac1a-1bfc648464f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA available: True\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"VWcDuwb6YmW4"},"execution_count":null,"outputs":[]}]}